{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets\n",
    "from collections import Counter\n",
    "\n",
    "from classic_vit import ViT\n",
    "from her2_dataset import HER2Dataset\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "transform = ToTensor()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "IMAGE_WIDTH = 28\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_CHANNELS = 1\n",
    "N_PATCHES = 14\n",
    "\n",
    "\n",
    "MAX_CHECKPOINTS = 3\n",
    "\n",
    "assert IMAGE_WIDTH%N_PATCHES==0\n",
    "\n",
    "PATCH_WIDTH = IMAGE_WIDTH//N_PATCHES\n",
    "PATCH_HEIGHT = IMAGE_HEIGHT//N_PATCHES\n",
    "\n",
    "\n",
    "DATASET_PATH='../datasets/HER2_gastric_3classes'\n",
    "# 20% of data goes to test\n",
    "TEST_SPLIT = 0.2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "N_EPOCHS = 5\n",
    "LR = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda (NVIDIA TITAN RTX)\n",
      "ROI divided into regions of 28x28x1\n",
      "Using 14x14 patches of 2x2x1\n",
      "101144330\n",
      "model size: 385.83MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "print(f\"ROI divided into regions of {IMAGE_WIDTH}x{IMAGE_HEIGHT}x{IMAGE_CHANNELS}\\nUsing {N_PATCHES}x{N_PATCHES} patches of {PATCH_WIDTH}x{PATCH_HEIGHT}x{IMAGE_CHANNELS}\")\n",
    "model = ViT(\n",
    "    in_channels=IMAGE_CHANNELS, \n",
    "    patch_size=PATCH_HEIGHT, \n",
    "    img_size=28,\n",
    "    n_classes=10, \n",
    "    dropout=0.1, \n",
    "    depth=128, \n",
    "    num_heads=8,\n",
    "    emb_size=256\n",
    ").to(device)\n",
    "#from vit_pytorch import ViT\n",
    "\n",
    "# model = ViT(\n",
    "#     image_size = 28,\n",
    "#     channels=1,\n",
    "#     patch_size = 14,\n",
    "#     num_classes = 10,\n",
    "#     dim = 1024,\n",
    "#     depth = 1,\n",
    "#     heads = 512,\n",
    "#     mlp_dim = 2048,\n",
    "#     dropout = 0.1,\n",
    "#     emb_dropout = 0.1\n",
    "# ).to(device)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "print(pytorch_total_params)\n",
    "\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print('model size: {:.2f}MB'.format(size_all_mb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 23.64 GiB total capacity; 22.57 GiB already allocated; 21.56 MiB free; 22.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m x, y \u001b[39m=\u001b[39m batch\n\u001b[1;32m      8\u001b[0m x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m y_hat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_hat, y)\n\u001b[1;32m     12\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._call_impl at line 1190 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/CustomViT-1/classic_vit.py:26\u001b[0m, in \u001b[0;36mResidualAdd.forward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     res \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 26\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     27\u001b[0m     x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m res\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/CustomViT-1/mulit_head_attention.py:42\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     40\u001b[0m scaling \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb_size \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     41\u001b[0m att \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(energy, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m scaling\n\u001b[0;32m---> 42\u001b[0m att \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49matt_drop(att)\n\u001b[1;32m     43\u001b[0m \u001b[39m# sum up over the third axis\u001b[39;00m\n\u001b[1;32m     44\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39meinsum(\u001b[39m'\u001b[39m\u001b[39mbhal, bhlv -> bhav \u001b[39m\u001b[39m'\u001b[39m, att, values)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[39mif\u001b[39;00m p \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m \u001b[39mor\u001b[39;00m p \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mdropout probability has to be between 0 and 1, \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39mdropout_(\u001b[39minput\u001b[39m, p, training) \u001b[39mif\u001b[39;00m inplace \u001b[39melse\u001b[39;00m _VF\u001b[39m.\u001b[39;49mdropout(\u001b[39minput\u001b[39;49m, p, training)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 23.64 GiB total capacity; 22.57 GiB already allocated; 21.56 MiB free; 22.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "optimizer = Adam(model.parameters(), lr=LR)\n",
    "criterion = CrossEntropyLoss()\n",
    "for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
    "    del loss\n",
    "    del x\n",
    "# Test loop\n",
    "with torch.no_grad():\n",
    "    correct, total = 0, 0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m y_true \u001b[39m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[39m# iterate over test data\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m test_loader:\n\u001b[1;32m     10\u001b[0m     output \u001b[39m=\u001b[39m model(inputs) \u001b[39m# Feed Network\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     output \u001b[39m=\u001b[39m (torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mexp(output), \u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "    \n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 2, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "[[  0  35   0]\n",
      " [  0 327   0]\n",
      " [  0  43   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "# constant for classes\n",
    "classes = dataset.classes\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
    "                    columns = [i for i in classes])\n",
    "plt.figure(figsize = (12,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 3\u001b[0m classification_report(y_pred\u001b[39m=\u001b[39;49my_pred, y_true\u001b[39m=\u001b[39;49my_true)\n",
      "File \u001b[0;32m~/miniconda3/envs/ds/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2185\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2184\u001b[0m     longest_last_line_heading \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mweighted avg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2185\u001b[0m     name_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(cn) \u001b[39mfor\u001b[39;49;00m cn \u001b[39min\u001b[39;49;00m target_names)\n\u001b[1;32m   2186\u001b[0m     width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(name_width, \u001b[39mlen\u001b[39m(longest_last_line_heading), digits)\n\u001b[1;32m   2187\u001b[0m     head_fmt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{\u001b[39m\u001b[39m:>\u001b[39m\u001b[39m{width}\u001b[39;00m\u001b[39ms} \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{:>9}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(headers)\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a16b647250300740897b4e39334bb57142d8ba69a9e070a33ebdb362a2c1397"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
